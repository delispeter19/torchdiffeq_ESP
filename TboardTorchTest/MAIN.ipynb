{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorboardX import SummaryWriter\n",
    "import numpy as np\n",
    "import scipy.misc \n",
    "from io import BytesIO  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logger(object):\n",
    "    \n",
    "    def __init__(self, log_dir):\n",
    "        \"\"\"Create a summary writer logging to log_dir.\"\"\"\n",
    "        self.writer = tf.summary.FileWriter(log_dir)\n",
    "        self.writerX = SummaryWriter(log_dir)\n",
    "        \n",
    "    def emb_summary(self, output):\n",
    "        out = torch.cat((output.data, torch.ones(len(output), 1)), 1)\n",
    "        self.writerX.add_embedding(out)\n",
    "        \n",
    "    def graph_summary(self, model, inputs):\n",
    "        self.writerX.add_graph(model, inputs, True)  \n",
    "        \n",
    "    def scalar_summary(self, tag, value, step):\n",
    "        \"\"\"Log a scalar variable.\"\"\"\n",
    "        summary = tf.Summary(value=[tf.Summary.Value(tag=tag, simple_value=value)])\n",
    "        self.writer.add_summary(summary, step)\n",
    "\n",
    "    def image_summary(self, tag, images, step):\n",
    "        \"\"\"Log a list of images.\"\"\"\n",
    "\n",
    "        img_summaries = []\n",
    "        for i, img in enumerate(images):\n",
    "            # Write the image to a string\n",
    "            try:\n",
    "                s = StringIO()\n",
    "            except:\n",
    "                s = BytesIO()\n",
    "            scipy.misc.toimage(img).save(s, format=\"png\")\n",
    "\n",
    "            # Create an Image object\n",
    "            img_sum = tf.Summary.Image(encoded_image_string=s.getvalue(),\n",
    "                                       height=img.shape[0],\n",
    "                                       width=img.shape[1])\n",
    "            # Create a Summary value\n",
    "            img_summaries.append(tf.Summary.Value(tag='%s/%d' % (tag, i), image=img_sum))\n",
    "\n",
    "        # Create and write Summary\n",
    "        summary = tf.Summary(value=img_summaries)\n",
    "        self.writer.add_summary(summary, step)\n",
    "        \n",
    "    def histo_summary(self, tag, values, step, bins=1000):\n",
    "        \"\"\"Log a histogram of the tensor of values.\"\"\"\n",
    "\n",
    "        # Create a histogram using numpy\n",
    "        counts, bin_edges = np.histogram(values, bins=bins)\n",
    "\n",
    "        # Fill the fields of the histogram proto\n",
    "        hist = tf.HistogramProto()\n",
    "        hist.min = float(np.min(values))\n",
    "        hist.max = float(np.max(values))\n",
    "        hist.num = int(np.prod(values.shape))\n",
    "        hist.sum = float(np.sum(values))\n",
    "        hist.sum_squares = float(np.sum(values**2))\n",
    "\n",
    "        # Drop the start of the first bin\n",
    "        bin_edges = bin_edges[1:]\n",
    "\n",
    "        # Add bin edges and counts\n",
    "        for edge in bin_edges:\n",
    "            hist.bucket_limit.append(edge)\n",
    "        for c in counts:\n",
    "            hist.bucket.append(c)\n",
    "\n",
    "        # Create and write Summary\n",
    "        summary = tf.Summary(value=[tf.Summary.Value(tag=tag, histo=hist)])\n",
    "        self.writer.add_summary(summary, step)\n",
    "        self.writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset \n",
    "dataset = torchvision.datasets.MNIST(root='../../data', \n",
    "                                     train=True, \n",
    "                                     transform=transforms.ToTensor(),  \n",
    "                                     download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader\n",
    "data_loader = torch.utils.data.DataLoader(dataset=dataset, \n",
    "                                          batch_size=100, \n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully connected neural network with one hidden layer\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size=784, hidden_size=500, num_classes=10):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet().to(device)\n",
    "\n",
    "logger = Logger('./logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = iter(data_loader)\n",
    "iter_per_epoch = len(data_loader)\n",
    "total_step = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [100/50000], Loss: 2.2184, Acc: 0.25\n",
      "graph(%input.1 : Float(100, 784)\n",
      "      %1 : Float(500, 784)\n",
      "      %2 : Float(500)\n",
      "      %3 : Float(10, 500)\n",
      "      %4 : Float(10)) {\n",
      "  %5 : Float(784!, 500!) = onnx::Transpose[perm=[1, 0]](%1), scope: NeuralNet/Linear[fc1]\n",
      "  %6 : Float(100, 500) = onnx::Gemm[alpha=1, beta=1](%input.1, %5, %2), scope: NeuralNet/Linear[fc1]\n",
      "  %7 : Float(100, 500) = onnx::Relu(%6), scope: NeuralNet/ReLU[relu]\n",
      "  %8 : Float(500!, 10!) = onnx::Transpose[perm=[1, 0]](%3), scope: NeuralNet/Linear[fc2]\n",
      "  %9 : Float(100, 10) = onnx::Gemm[alpha=1, beta=1](%7, %8, %4), scope: NeuralNet/Linear[fc2]\n",
      "  return (%9);\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\delis\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: DeprecationWarning: `toimage` is deprecated!\n",
      "`toimage` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use Pillow's ``Image.fromarray`` directly instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [200/50000], Loss: 2.1100, Acc: 0.58\n",
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "graph(%input.1 : Float(100, 784)\n",
      "      %1 : Float(500, 784)\n",
      "      %2 : Float(500)\n",
      "      %3 : Float(10, 500)\n",
      "      %4 : Float(10)) {\n",
      "  %5 : Float(784!, 500!) = onnx::Transpose[perm=[1, 0]](%1), scope: NeuralNet/Linear[fc1]\n",
      "  %6 : Float(100, 500) = onnx::Gemm[alpha=1, beta=1](%input.1, %5, %2), scope: NeuralNet/Linear[fc1]\n",
      "  %7 : Float(100, 500) = onnx::Relu(%6), scope: NeuralNet/ReLU[relu]\n",
      "  %8 : Float(500!, 10!) = onnx::Transpose[perm=[1, 0]](%3), scope: NeuralNet/Linear[fc2]\n",
      "  %9 : Float(100, 10) = onnx::Gemm[alpha=1, beta=1](%7, %8, %4), scope: NeuralNet/Linear[fc2]\n",
      "  return (%9);\n",
      "}\n",
      "\n",
      "Step [300/50000], Loss: 1.9927, Acc: 0.63\n",
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "graph(%input.1 : Float(100, 784)\n",
      "      %1 : Float(500, 784)\n",
      "      %2 : Float(500)\n",
      "      %3 : Float(10, 500)\n",
      "      %4 : Float(10)) {\n",
      "  %5 : Float(784!, 500!) = onnx::Transpose[perm=[1, 0]](%1), scope: NeuralNet/Linear[fc1]\n",
      "  %6 : Float(100, 500) = onnx::Gemm[alpha=1, beta=1](%input.1, %5, %2), scope: NeuralNet/Linear[fc1]\n",
      "  %7 : Float(100, 500) = onnx::Relu(%6), scope: NeuralNet/ReLU[relu]\n",
      "  %8 : Float(500!, 10!) = onnx::Transpose[perm=[1, 0]](%3), scope: NeuralNet/Linear[fc2]\n",
      "  %9 : Float(100, 10) = onnx::Gemm[alpha=1, beta=1](%7, %8, %4), scope: NeuralNet/Linear[fc2]\n",
      "  return (%9);\n",
      "}\n",
      "\n",
      "Step [400/50000], Loss: 1.8629, Acc: 0.72\n",
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "graph(%input.1 : Float(100, 784)\n",
      "      %1 : Float(500, 784)\n",
      "      %2 : Float(500)\n",
      "      %3 : Float(10, 500)\n",
      "      %4 : Float(10)) {\n",
      "  %5 : Float(784!, 500!) = onnx::Transpose[perm=[1, 0]](%1), scope: NeuralNet/Linear[fc1]\n",
      "  %6 : Float(100, 500) = onnx::Gemm[alpha=1, beta=1](%input.1, %5, %2), scope: NeuralNet/Linear[fc1]\n",
      "  %7 : Float(100, 500) = onnx::Relu(%6), scope: NeuralNet/ReLU[relu]\n",
      "  %8 : Float(500!, 10!) = onnx::Transpose[perm=[1, 0]](%3), scope: NeuralNet/Linear[fc2]\n",
      "  %9 : Float(100, 10) = onnx::Gemm[alpha=1, beta=1](%7, %8, %4), scope: NeuralNet/Linear[fc2]\n",
      "  return (%9);\n",
      "}\n",
      "\n",
      "Step [500/50000], Loss: 1.6782, Acc: 0.83\n",
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "graph(%input.1 : Float(100, 784)\n",
      "      %1 : Float(500, 784)\n",
      "      %2 : Float(500)\n",
      "      %3 : Float(10, 500)\n",
      "      %4 : Float(10)) {\n",
      "  %5 : Float(784!, 500!) = onnx::Transpose[perm=[1, 0]](%1), scope: NeuralNet/Linear[fc1]\n",
      "  %6 : Float(100, 500) = onnx::Gemm[alpha=1, beta=1](%input.1, %5, %2), scope: NeuralNet/Linear[fc1]\n",
      "  %7 : Float(100, 500) = onnx::Relu(%6), scope: NeuralNet/ReLU[relu]\n",
      "  %8 : Float(500!, 10!) = onnx::Transpose[perm=[1, 0]](%3), scope: NeuralNet/Linear[fc2]\n",
      "  %9 : Float(100, 10) = onnx::Gemm[alpha=1, beta=1](%7, %8, %4), scope: NeuralNet/Linear[fc2]\n",
      "  return (%9);\n",
      "}\n",
      "\n",
      "Step [600/50000], Loss: 1.6324, Acc: 0.74\n",
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "graph(%input.1 : Float(100, 784)\n",
      "      %1 : Float(500, 784)\n",
      "      %2 : Float(500)\n",
      "      %3 : Float(10, 500)\n",
      "      %4 : Float(10)) {\n",
      "  %5 : Float(784!, 500!) = onnx::Transpose[perm=[1, 0]](%1), scope: NeuralNet/Linear[fc1]\n",
      "  %6 : Float(100, 500) = onnx::Gemm[alpha=1, beta=1](%input.1, %5, %2), scope: NeuralNet/Linear[fc1]\n",
      "  %7 : Float(100, 500) = onnx::Relu(%6), scope: NeuralNet/ReLU[relu]\n",
      "  %8 : Float(500!, 10!) = onnx::Transpose[perm=[1, 0]](%3), scope: NeuralNet/Linear[fc2]\n",
      "  %9 : Float(100, 10) = onnx::Gemm[alpha=1, beta=1](%7, %8, %4), scope: NeuralNet/Linear[fc2]\n",
      "  return (%9);\n",
      "}\n",
      "\n",
      "Step [700/50000], Loss: 1.4930, Acc: 0.74\n",
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "graph(%input.1 : Float(100, 784)\n",
      "      %1 : Float(500, 784)\n",
      "      %2 : Float(500)\n",
      "      %3 : Float(10, 500)\n",
      "      %4 : Float(10)) {\n",
      "  %5 : Float(784!, 500!) = onnx::Transpose[perm=[1, 0]](%1), scope: NeuralNet/Linear[fc1]\n",
      "  %6 : Float(100, 500) = onnx::Gemm[alpha=1, beta=1](%input.1, %5, %2), scope: NeuralNet/Linear[fc1]\n",
      "  %7 : Float(100, 500) = onnx::Relu(%6), scope: NeuralNet/ReLU[relu]\n",
      "  %8 : Float(500!, 10!) = onnx::Transpose[perm=[1, 0]](%3), scope: NeuralNet/Linear[fc2]\n",
      "  %9 : Float(100, 10) = onnx::Gemm[alpha=1, beta=1](%7, %8, %4), scope: NeuralNet/Linear[fc2]\n",
      "  return (%9);\n",
      "}\n",
      "\n",
      "Step [800/50000], Loss: 1.3416, Acc: 0.84\n",
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "graph(%input.1 : Float(100, 784)\n",
      "      %1 : Float(500, 784)\n",
      "      %2 : Float(500)\n",
      "      %3 : Float(10, 500)\n",
      "      %4 : Float(10)) {\n",
      "  %5 : Float(784!, 500!) = onnx::Transpose[perm=[1, 0]](%1), scope: NeuralNet/Linear[fc1]\n",
      "  %6 : Float(100, 500) = onnx::Gemm[alpha=1, beta=1](%input.1, %5, %2), scope: NeuralNet/Linear[fc1]\n",
      "  %7 : Float(100, 500) = onnx::Relu(%6), scope: NeuralNet/ReLU[relu]\n",
      "  %8 : Float(500!, 10!) = onnx::Transpose[perm=[1, 0]](%3), scope: NeuralNet/Linear[fc2]\n",
      "  %9 : Float(100, 10) = onnx::Gemm[alpha=1, beta=1](%7, %8, %4), scope: NeuralNet/Linear[fc2]\n",
      "  return (%9);\n",
      "}\n",
      "\n",
      "Step [900/50000], Loss: 1.3903, Acc: 0.78\n",
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "graph(%input.1 : Float(100, 784)\n",
      "      %1 : Float(500, 784)\n",
      "      %2 : Float(500)\n",
      "      %3 : Float(10, 500)\n",
      "      %4 : Float(10)) {\n",
      "  %5 : Float(784!, 500!) = onnx::Transpose[perm=[1, 0]](%1), scope: NeuralNet/Linear[fc1]\n",
      "  %6 : Float(100, 500) = onnx::Gemm[alpha=1, beta=1](%input.1, %5, %2), scope: NeuralNet/Linear[fc1]\n",
      "  %7 : Float(100, 500) = onnx::Relu(%6), scope: NeuralNet/ReLU[relu]\n",
      "  %8 : Float(500!, 10!) = onnx::Transpose[perm=[1, 0]](%3), scope: NeuralNet/Linear[fc2]\n",
      "  %9 : Float(100, 10) = onnx::Gemm[alpha=1, beta=1](%7, %8, %4), scope: NeuralNet/Linear[fc2]\n",
      "  return (%9);\n",
      "}\n",
      "\n",
      "Step [1000/50000], Loss: 1.1939, Acc: 0.81\n",
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "graph(%input.1 : Float(100, 784)\n",
      "      %1 : Float(500, 784)\n",
      "      %2 : Float(500)\n",
      "      %3 : Float(10, 500)\n",
      "      %4 : Float(10)) {\n",
      "  %5 : Float(784!, 500!) = onnx::Transpose[perm=[1, 0]](%1), scope: NeuralNet/Linear[fc1]\n",
      "  %6 : Float(100, 500) = onnx::Gemm[alpha=1, beta=1](%input.1, %5, %2), scope: NeuralNet/Linear[fc1]\n",
      "  %7 : Float(100, 500) = onnx::Relu(%6), scope: NeuralNet/ReLU[relu]\n",
      "  %8 : Float(500!, 10!) = onnx::Transpose[perm=[1, 0]](%3), scope: NeuralNet/Linear[fc2]\n",
      "  %9 : Float(100, 10) = onnx::Gemm[alpha=1, beta=1](%7, %8, %4), scope: NeuralNet/Linear[fc2]\n",
      "  return (%9);\n",
      "}\n",
      "\n",
      "Step [1100/50000], Loss: 1.1576, Acc: 0.80\n",
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "graph(%input.1 : Float(100, 784)\n",
      "      %1 : Float(500, 784)\n",
      "      %2 : Float(500)\n",
      "      %3 : Float(10, 500)\n",
      "      %4 : Float(10)) {\n",
      "  %5 : Float(784!, 500!) = onnx::Transpose[perm=[1, 0]](%1), scope: NeuralNet/Linear[fc1]\n",
      "  %6 : Float(100, 500) = onnx::Gemm[alpha=1, beta=1](%input.1, %5, %2), scope: NeuralNet/Linear[fc1]\n",
      "  %7 : Float(100, 500) = onnx::Relu(%6), scope: NeuralNet/ReLU[relu]\n",
      "  %8 : Float(500!, 10!) = onnx::Transpose[perm=[1, 0]](%3), scope: NeuralNet/Linear[fc2]\n",
      "  %9 : Float(100, 10) = onnx::Gemm[alpha=1, beta=1](%7, %8, %4), scope: NeuralNet/Linear[fc2]\n",
      "  return (%9);\n",
      "}\n",
      "\n",
      "Step [1200/50000], Loss: 0.9880, Acc: 0.86\n",
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "graph(%input.1 : Float(100, 784)\n",
      "      %1 : Float(500, 784)\n",
      "      %2 : Float(500)\n",
      "      %3 : Float(10, 500)\n",
      "      %4 : Float(10)) {\n",
      "  %5 : Float(784!, 500!) = onnx::Transpose[perm=[1, 0]](%1), scope: NeuralNet/Linear[fc1]\n",
      "  %6 : Float(100, 500) = onnx::Gemm[alpha=1, beta=1](%input.1, %5, %2), scope: NeuralNet/Linear[fc1]\n",
      "  %7 : Float(100, 500) = onnx::Relu(%6), scope: NeuralNet/ReLU[relu]\n",
      "  %8 : Float(500!, 10!) = onnx::Transpose[perm=[1, 0]](%3), scope: NeuralNet/Linear[fc2]\n",
      "  %9 : Float(100, 10) = onnx::Gemm[alpha=1, beta=1](%7, %8, %4), scope: NeuralNet/Linear[fc2]\n",
      "  return (%9);\n",
      "}\n",
      "\n",
      "Step [1300/50000], Loss: 1.1254, Acc: 0.76\n",
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "graph(%input.1 : Float(100, 784)\n",
      "      %1 : Float(500, 784)\n",
      "      %2 : Float(500)\n",
      "      %3 : Float(10, 500)\n",
      "      %4 : Float(10)) {\n",
      "  %5 : Float(784!, 500!) = onnx::Transpose[perm=[1, 0]](%1), scope: NeuralNet/Linear[fc1]\n",
      "  %6 : Float(100, 500) = onnx::Gemm[alpha=1, beta=1](%input.1, %5, %2), scope: NeuralNet/Linear[fc1]\n",
      "  %7 : Float(100, 500) = onnx::Relu(%6), scope: NeuralNet/ReLU[relu]\n",
      "  %8 : Float(500!, 10!) = onnx::Transpose[perm=[1, 0]](%3), scope: NeuralNet/Linear[fc2]\n",
      "  %9 : Float(100, 10) = onnx::Gemm[alpha=1, beta=1](%7, %8, %4), scope: NeuralNet/Linear[fc2]\n",
      "  return (%9);\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step [1400/50000], Loss: 1.0117, Acc: 0.79\n",
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "graph(%input.1 : Float(100, 784)\n",
      "      %1 : Float(500, 784)\n",
      "      %2 : Float(500)\n",
      "      %3 : Float(10, 500)\n",
      "      %4 : Float(10)) {\n",
      "  %5 : Float(784!, 500!) = onnx::Transpose[perm=[1, 0]](%1), scope: NeuralNet/Linear[fc1]\n",
      "  %6 : Float(100, 500) = onnx::Gemm[alpha=1, beta=1](%input.1, %5, %2), scope: NeuralNet/Linear[fc1]\n",
      "  %7 : Float(100, 500) = onnx::Relu(%6), scope: NeuralNet/ReLU[relu]\n",
      "  %8 : Float(500!, 10!) = onnx::Transpose[perm=[1, 0]](%3), scope: NeuralNet/Linear[fc2]\n",
      "  %9 : Float(100, 10) = onnx::Gemm[alpha=1, beta=1](%7, %8, %4), scope: NeuralNet/Linear[fc2]\n",
      "  return (%9);\n",
      "}\n",
      "\n",
      "Step [1500/50000], Loss: 0.9393, Acc: 0.84\n",
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "graph(%input.1 : Float(100, 784)\n",
      "      %1 : Float(500, 784)\n",
      "      %2 : Float(500)\n",
      "      %3 : Float(10, 500)\n",
      "      %4 : Float(10)) {\n",
      "  %5 : Float(784!, 500!) = onnx::Transpose[perm=[1, 0]](%1), scope: NeuralNet/Linear[fc1]\n",
      "  %6 : Float(100, 500) = onnx::Gemm[alpha=1, beta=1](%input.1, %5, %2), scope: NeuralNet/Linear[fc1]\n",
      "  %7 : Float(100, 500) = onnx::Relu(%6), scope: NeuralNet/ReLU[relu]\n",
      "  %8 : Float(500!, 10!) = onnx::Transpose[perm=[1, 0]](%3), scope: NeuralNet/Linear[fc2]\n",
      "  %9 : Float(100, 10) = onnx::Gemm[alpha=1, beta=1](%7, %8, %4), scope: NeuralNet/Linear[fc2]\n",
      "  return (%9);\n",
      "}\n",
      "\n",
      "Step [1600/50000], Loss: 0.8557, Acc: 0.85\n",
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "graph(%input.1 : Float(100, 784)\n",
      "      %1 : Float(500, 784)\n",
      "      %2 : Float(500)\n",
      "      %3 : Float(10, 500)\n",
      "      %4 : Float(10)) {\n",
      "  %5 : Float(784!, 500!) = onnx::Transpose[perm=[1, 0]](%1), scope: NeuralNet/Linear[fc1]\n",
      "  %6 : Float(100, 500) = onnx::Gemm[alpha=1, beta=1](%input.1, %5, %2), scope: NeuralNet/Linear[fc1]\n",
      "  %7 : Float(100, 500) = onnx::Relu(%6), scope: NeuralNet/ReLU[relu]\n",
      "  %8 : Float(500!, 10!) = onnx::Transpose[perm=[1, 0]](%3), scope: NeuralNet/Linear[fc2]\n",
      "  %9 : Float(100, 10) = onnx::Gemm[alpha=1, beta=1](%7, %8, %4), scope: NeuralNet/Linear[fc2]\n",
      "  return (%9);\n",
      "}\n",
      "\n",
      "Step [1700/50000], Loss: 0.7902, Acc: 0.86\n",
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "graph(%input.1 : Float(100, 784)\n",
      "      %1 : Float(500, 784)\n",
      "      %2 : Float(500)\n",
      "      %3 : Float(10, 500)\n",
      "      %4 : Float(10)) {\n",
      "  %5 : Float(784!, 500!) = onnx::Transpose[perm=[1, 0]](%1), scope: NeuralNet/Linear[fc1]\n",
      "  %6 : Float(100, 500) = onnx::Gemm[alpha=1, beta=1](%input.1, %5, %2), scope: NeuralNet/Linear[fc1]\n",
      "  %7 : Float(100, 500) = onnx::Relu(%6), scope: NeuralNet/ReLU[relu]\n",
      "  %8 : Float(500!, 10!) = onnx::Transpose[perm=[1, 0]](%3), scope: NeuralNet/Linear[fc2]\n",
      "  %9 : Float(100, 10) = onnx::Gemm[alpha=1, beta=1](%7, %8, %4), scope: NeuralNet/Linear[fc2]\n",
      "  return (%9);\n",
      "}\n",
      "\n",
      "Step [1800/50000], Loss: 0.8342, Acc: 0.83\n",
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "graph(%input.1 : Float(100, 784)\n",
      "      %1 : Float(500, 784)\n",
      "      %2 : Float(500)\n",
      "      %3 : Float(10, 500)\n",
      "      %4 : Float(10)) {\n",
      "  %5 : Float(784!, 500!) = onnx::Transpose[perm=[1, 0]](%1), scope: NeuralNet/Linear[fc1]\n",
      "  %6 : Float(100, 500) = onnx::Gemm[alpha=1, beta=1](%input.1, %5, %2), scope: NeuralNet/Linear[fc1]\n",
      "  %7 : Float(100, 500) = onnx::Relu(%6), scope: NeuralNet/ReLU[relu]\n",
      "  %8 : Float(500!, 10!) = onnx::Transpose[perm=[1, 0]](%3), scope: NeuralNet/Linear[fc2]\n",
      "  %9 : Float(100, 10) = onnx::Gemm[alpha=1, beta=1](%7, %8, %4), scope: NeuralNet/Linear[fc2]\n",
      "  return (%9);\n",
      "}\n",
      "\n",
      "Step [1900/50000], Loss: 0.7867, Acc: 0.83\n",
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "graph(%input.1 : Float(100, 784)\n",
      "      %1 : Float(500, 784)\n",
      "      %2 : Float(500)\n",
      "      %3 : Float(10, 500)\n",
      "      %4 : Float(10)) {\n",
      "  %5 : Float(784!, 500!) = onnx::Transpose[perm=[1, 0]](%1), scope: NeuralNet/Linear[fc1]\n",
      "  %6 : Float(100, 500) = onnx::Gemm[alpha=1, beta=1](%input.1, %5, %2), scope: NeuralNet/Linear[fc1]\n",
      "  %7 : Float(100, 500) = onnx::Relu(%6), scope: NeuralNet/ReLU[relu]\n",
      "  %8 : Float(500!, 10!) = onnx::Transpose[perm=[1, 0]](%3), scope: NeuralNet/Linear[fc2]\n",
      "  %9 : Float(100, 10) = onnx::Gemm[alpha=1, beta=1](%7, %8, %4), scope: NeuralNet/Linear[fc2]\n",
      "  return (%9);\n",
      "}\n",
      "\n",
      "Step [2000/50000], Loss: 0.7591, Acc: 0.84\n",
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "graph(%input.1 : Float(100, 784)\n",
      "      %1 : Float(500, 784)\n",
      "      %2 : Float(500)\n",
      "      %3 : Float(10, 500)\n",
      "      %4 : Float(10)) {\n",
      "  %5 : Float(784!, 500!) = onnx::Transpose[perm=[1, 0]](%1), scope: NeuralNet/Linear[fc1]\n",
      "  %6 : Float(100, 500) = onnx::Gemm[alpha=1, beta=1](%input.1, %5, %2), scope: NeuralNet/Linear[fc1]\n",
      "  %7 : Float(100, 500) = onnx::Relu(%6), scope: NeuralNet/ReLU[relu]\n",
      "  %8 : Float(500!, 10!) = onnx::Transpose[perm=[1, 0]](%3), scope: NeuralNet/Linear[fc2]\n",
      "  %9 : Float(100, 10) = onnx::Gemm[alpha=1, beta=1](%7, %8, %4), scope: NeuralNet/Linear[fc2]\n",
      "  return (%9);\n",
      "}\n",
      "\n",
      "Step [2100/50000], Loss: 0.7230, Acc: 0.83\n",
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "graph(%input.1 : Float(100, 784)\n",
      "      %1 : Float(500, 784)\n",
      "      %2 : Float(500)\n",
      "      %3 : Float(10, 500)\n",
      "      %4 : Float(10)) {\n",
      "  %5 : Float(784!, 500!) = onnx::Transpose[perm=[1, 0]](%1), scope: NeuralNet/Linear[fc1]\n",
      "  %6 : Float(100, 500) = onnx::Gemm[alpha=1, beta=1](%input.1, %5, %2), scope: NeuralNet/Linear[fc1]\n",
      "  %7 : Float(100, 500) = onnx::Relu(%6), scope: NeuralNet/ReLU[relu]\n",
      "  %8 : Float(500!, 10!) = onnx::Transpose[perm=[1, 0]](%3), scope: NeuralNet/Linear[fc2]\n",
      "  %9 : Float(100, 10) = onnx::Gemm[alpha=1, beta=1](%7, %8, %4), scope: NeuralNet/Linear[fc2]\n",
      "  return (%9);\n",
      "}\n",
      "\n",
      "Step [2200/50000], Loss: 0.7236, Acc: 0.86\n",
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "graph(%input.1 : Float(100, 784)\n",
      "      %1 : Float(500, 784)\n",
      "      %2 : Float(500)\n",
      "      %3 : Float(10, 500)\n",
      "      %4 : Float(10)) {\n",
      "  %5 : Float(784!, 500!) = onnx::Transpose[perm=[1, 0]](%1), scope: NeuralNet/Linear[fc1]\n",
      "  %6 : Float(100, 500) = onnx::Gemm[alpha=1, beta=1](%input.1, %5, %2), scope: NeuralNet/Linear[fc1]\n",
      "  %7 : Float(100, 500) = onnx::Relu(%6), scope: NeuralNet/ReLU[relu]\n",
      "  %8 : Float(500!, 10!) = onnx::Transpose[perm=[1, 0]](%3), scope: NeuralNet/Linear[fc2]\n",
      "  %9 : Float(100, 10) = onnx::Gemm[alpha=1, beta=1](%7, %8, %4), scope: NeuralNet/Linear[fc2]\n",
      "  return (%9);\n",
      "}\n",
      "\n",
      "Step [2300/50000], Loss: 0.7027, Acc: 0.85\n",
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "graph(%input.1 : Float(100, 784)\n",
      "      %1 : Float(500, 784)\n",
      "      %2 : Float(500)\n",
      "      %3 : Float(10, 500)\n",
      "      %4 : Float(10)) {\n",
      "  %5 : Float(784!, 500!) = onnx::Transpose[perm=[1, 0]](%1), scope: NeuralNet/Linear[fc1]\n",
      "  %6 : Float(100, 500) = onnx::Gemm[alpha=1, beta=1](%input.1, %5, %2), scope: NeuralNet/Linear[fc1]\n",
      "  %7 : Float(100, 500) = onnx::Relu(%6), scope: NeuralNet/ReLU[relu]\n",
      "  %8 : Float(500!, 10!) = onnx::Transpose[perm=[1, 0]](%3), scope: NeuralNet/Linear[fc2]\n",
      "  %9 : Float(100, 10) = onnx::Gemm[alpha=1, beta=1](%7, %8, %4), scope: NeuralNet/Linear[fc2]\n",
      "  return (%9);\n",
      "}\n",
      "\n",
      "Step [2400/50000], Loss: 0.6016, Acc: 0.87\n",
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "graph(%input.1 : Float(100, 784)\n",
      "      %1 : Float(500, 784)\n",
      "      %2 : Float(500)\n",
      "      %3 : Float(10, 500)\n",
      "      %4 : Float(10)) {\n",
      "  %5 : Float(784!, 500!) = onnx::Transpose[perm=[1, 0]](%1), scope: NeuralNet/Linear[fc1]\n",
      "  %6 : Float(100, 500) = onnx::Gemm[alpha=1, beta=1](%input.1, %5, %2), scope: NeuralNet/Linear[fc1]\n",
      "  %7 : Float(100, 500) = onnx::Relu(%6), scope: NeuralNet/ReLU[relu]\n",
      "  %8 : Float(500!, 10!) = onnx::Transpose[perm=[1, 0]](%3), scope: NeuralNet/Linear[fc2]\n",
      "  %9 : Float(100, 10) = onnx::Gemm[alpha=1, beta=1](%7, %8, %4), scope: NeuralNet/Linear[fc2]\n",
      "  return (%9);\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "for step in range(total_step):\n",
    "    \n",
    "    # Reset the data_iter\n",
    "    if (step+1) % iter_per_epoch == 0:\n",
    "        data_iter = iter(data_loader)\n",
    "\n",
    "    # Fetch images and labels\n",
    "    images, labels = next(data_iter)\n",
    "    images, labels = images.view(images.size(0), -1).to(device), labels.to(device)\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = model(images)\n",
    "    loss = criterion(outputs, labels)\n",
    "    \n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Compute accuracy\n",
    "    _, argmax = torch.max(outputs, 1)\n",
    "    accuracy = (labels == argmax.squeeze()).float().mean()\n",
    "\n",
    "    if (step+1) % 100 == 0:\n",
    "        print ('Step [{}/{}], Loss: {:.4f}, Acc: {:.2f}' \n",
    "               .format(step+1, total_step, loss.item(), accuracy.item()))\n",
    "\n",
    "        # ================================================================== #\n",
    "        #                        Tensorboard Logging                         #\n",
    "        # ================================================================== #\n",
    "        \n",
    "        logger.emb_summary(outputs)\n",
    "        \n",
    "        logger.graph_summary(model,images)\n",
    "\n",
    "        # 1. Log scalar values (scalar summary)\n",
    "        info = { 'loss': loss.item(), 'accuracy': accuracy.item() }\n",
    "\n",
    "        for tag, value in info.items():\n",
    "            logger.scalar_summary(tag, value, step+1)\n",
    "\n",
    "        # 2. Log values and gradients of the parameters (histogram summary)\n",
    "        for tag, value in model.named_parameters():\n",
    "            tag = tag.replace('.', '/')\n",
    "            logger.histo_summary(tag, value.data.cpu().numpy(), step+1)\n",
    "            logger.histo_summary(tag+'/grad', value.grad.data.cpu().numpy(), step+1)\n",
    "\n",
    "        # 3. Log training images (image summary)\n",
    "        info = { 'images': images.view(-1, 28, 28)[:10].cpu().numpy() }\n",
    "\n",
    "        for tag, images in info.items():\n",
    "            logger.image_summary(tag, images, step+1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
